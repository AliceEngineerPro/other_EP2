# 联邦学习的分类

随着 AlphaGo 击败了顶尖的人类围棋玩家，我们见证了人工智能（AI）的巨大潜力，并开始期待将更复杂、更尖端的人工智能技术应用在其它领域，包括无人驾驶汽车、医疗、金融等。然而，今天的人工智能仍面临两大挑战：
- 其一是，在大多数行业中，数据以孤岛的形式存在；
- 其二是数据隐私和安全。

我们提出了一个可能的解决方案：**安全的联邦学习**。
联邦学习包括通过远程设备或孤立的数据中心（如移动电话或医院）训练统计模型，同时保持数据本地化。

在异构和潜在的大规模网络中进行训练带来了新的挑战，这些挑战要求从根本上背离大规模机器学习、分布式优化和隐私保护数据分析的标准方法。

除了 Google 在 2016 年首次提出的联邦学习框架外，我们还引入了一个全面的安全联邦学习框架，包括横向联邦学习、纵向联邦学习和联邦迁移学习。

我们提供了联邦学习框架的定义、结构和应用，然后讨论了联邦学习的独特特性和挑战，并对当前的方法进行了广泛的概述，最后概述了与广泛的研究社区相关的未来工作的几个方向。

此外，我们提出在组织间建立基于联邦机制的数据网络，作为一个有效的解决方案，允许知识在不损害用户隐私的情况下共享。

![](https://imgbed.momodel.cn/lkx10.png)

首先我们将讨论如何根据数据的分布特征对联邦学习进行分类。

令矩阵 Di 表示每个数据所有者 i 持有的数据。矩阵的每一行表示一个样本，每一列表示一个特征。
同时，一些数据集也可能包含标签数据。我们用 X 表示特征空间，用 Y 表示标签空间，用 I 表示样本 ID 空间。

例如，在金融领域，标签可以是用户的信用；在营销领域，标签可以是用户的购买欲望；在教育领域，标签可以是学生的学位。

特征 X、标签 Y 和样本 I 构成完整的训练数据集（I, X, Y）。

数据方的特征和样本空间可能不完全相同，根据数据在特征和样本ID空间中的分布情况，我们将联邦学习分为**横向联邦学习**、**纵向联邦学习**和**联邦迁移学习**。

## 1. 横向联邦学习(Horizontal Federated Learning)

![](https://imgbed.momodel.cn/lkx11.png)

**横向联邦学习，或者基于样本的联邦学习，被引入到数据集共享相同的特征空间，但样本不同的场景中**。

例如，两个区域性银行的用户组可能由于各自的区域不同，其用户的交叉集非常小。但是，它们的业务非常相似，因此特征空间是相同的。  
有研究提出了一个协作式深度学习方案，参与者独立训练，只共享参数更新的子集。  
2017年，谷歌提出了一个横向联邦学习解决方案，用于 Android 手机模型更新。  
在该框架中，使用 Android 手机的单个用户在本地更新模型参数，并将参数上传到 Android 云，从而与其他数据所有者共同训练中心化模型。  
此外，谷歌还提出了一种安全聚合方案，以保护在联邦学习框架下聚合用户更新的隐私。甚至，学者对模型参数聚合使用加法同态加密来提供对中央服务器的安全性。  
有研究者提出了一种多任务风格的联邦学习系统，允许多个站点在共享知识和维护安全的同时完成不同的任务  
他们提出的多任务学习模型还可以解决高通信成本、掉队者和容错问题。  
有的学者提出构建一个安全的客户机-服务器结构。在该结构中，联邦学习系统按用户划分数据，并允许在客户机设备上构建模型（确保了数据不泄漏），在服务器站点上协作以构建一个全局联邦模型。  
同样，有学者提出了提高通信成本，以便于基于分布在移动客户端上的数据对训练得到中心化模型的方法。  
近年来，为了在大规模分布式训练中大幅度降低通信带宽，有研究提出了一种称为深度梯度压缩的压缩方法。

### 1.1 横向联邦学习的架构

![](https://imgbed.momodel.cn/lkx15.png)

横向联邦学习系统的典型架构上图所示。在该系统中，具有相同数据结构的 k 个参与者通过参数或云服务器协同学习机器学习模型。  
一个典型的假设是参与者是诚实的，而服务器是诚实但好奇的，因此不允许任何参与者向服务器泄漏信息。  
这种系统的训练过程通常包括以下四个步骤：

**第一步：** 参与者在本地计算训练梯度，使用加密、差异隐私或秘密共享技术掩饰所选梯度，并将掩码后的结果发送到服务器；  
**第二步：** 服务器执行安全聚合，不了解任何参与者的信息  
**第三步：** 服务器将汇总后的结果发送给参与者  
**第四步：** 参与者用解密的梯度更新他们各自的模型

通过上述步骤进行迭代，直到损失函数收敛，从而完成整个训练过程。该结构独立于特定的机器学习算法（逻辑回归、DNN等），所有参与者将共享最终的模型参数。

**安全性分析：** 如果梯度聚合是使用安全多方计算（SMC）或同态加密完成的，则证明上述结构可以保护数据泄漏不受半诚实服务器的影响。但它可能会受到另一种安全模式的攻击，即恶意参与者在协作学习过程中训练生成对抗网络（GAN）。

在不同应用场景下，我们对横向联邦学习技术的要求也有一些区别：

1）智能手机：以谷歌为代表的研究主要涉及的是安全聚合技术，中央参数服务器可以知道聚合后的参数和模型，但是不知道每一个参与者具体的信息；此外，在中央参数服务器也可以提供数据参与整个训练过程，联邦学习是对中央参数服务器中已有数据的一个很好的数据补充，能够有效地提高模型性能  
2）组织：以微众为代表的研究主要涉及的是同态加密技术，中央参数服务器无法知道聚合后的参数和模型（有时候该条件可以放宽），最大程度上保护了参与方的隐私；此外，这里中央参数服务器一般无法参与训练，其作用就是对加密后的参数进行聚合与分发等。

### 1.2 横向联邦学习的典型应用

**智能手机：** 通过在大量移动电话中联邦学习用户行为，统计模型可以为诸如下一个单词预测、人脸检测和语音识别等应用提供动力。然而为了保护个人隐私或节省手机有限的带宽/电池电量，用户可能不愿意共享数据。联邦学习有可能在智能手机上实现预测功能，而不会降低用户体验或泄露用户信息。 

**组织：** 在联邦学习的背景下，组织或机构也可以被视为“设备”。例如，医院是包含大量患者数据的组织，用于预测医疗保健。然而，医院在严格的隐私措施下运营，可能会面临法律、行政或道德约束，这些约束要求数据保持本地。联邦学习对于这些应用来说是一个很有前途的解决方案，因为它可以减少网络上的压力，并支持各种设备/组织之间的私有学习。  

**物联网：** 现代物联网，如可穿戴设备、自主车辆或智慧家庭，可能包含许多传感器，使他们能够收集、反应和适应实时输入的数据。例如，一组自主车辆可能需要最新的交通、建筑或行人行为模型才能安全运行。然而，由于数据的私密性和每个设备的有限连接，在这些场景中构建聚合模型可能很困难。联邦学习方法有助于训练模型，使其能够有效地适应这些系统中的变化，同时保持用户隐私。

## 2. 纵向联邦学习（Vertically Federated Learning）

![](https://imgbed.momodel.cn/lkx14.png)

**纵向联邦学习，或基于特征的联邦学习，适用于两个数据集共享相同的样本 ID 空间，但特征空间不同的情况。**                        
例如，考虑同一城市中的两个不同公司，一个是银行，另一个是电子商务公司。他们的用户集可能包含该区域的大多数居民，因此他们的用户空间的交叉很大。  
然而，由于银行记录了用户的收支行为和信用评级，电子商务保留了用户的浏览和购买历史，所以其特征空间有很大的不同。  
假设我们希望双方都有一个基于用户和产品信息的产品购买预测模型。  
纵向联邦学习是将这些不同的特征聚合在一起，以一种隐私保护的方式计算训练损失和梯度的过程，以便用双方的数据协作构建一个模型。  
在这种联邦机制下，每个参与方的身份和地位是相同的，联邦系统帮助每个人建立“共同财富”策略，这就是为什么这个系统被称为“联邦学习”。  

**纵向联邦学习的架构与流程**

假设 A 公司和 B 公司想要联合训练一个机器学习模型，并且他们的业务系统都有自己的数据。  
此外，B 公司还拥有模型需要预测的标签数据。  
由于数据隐私和安全原因，A 和 B 不能直接交换数据。为了确保训练过程中数据的保密性，引入了第三方合作者 C。  
在此，我们假设合作者 C 是诚实的，不与 A 或 B 勾结，但 A 和 B 是诚实但彼此好奇的。  
一个可信的第三方 C 是一个合理的假设，因为 C 可以由政府等权威机构发挥作用，或由安全计算节点，如 Intel Software Guard Extensions（SGX）取代。联邦学习系统由两部分组成，如图4所示。 

![](https://imgbed.momodel.cn/lkx16.png)

**PART 1：** 加密实体对齐。由于两家公司的用户组不同，系统使用基于加密的用户 ID 对齐技术，来确认双方的共同用户，而 A 和 B 不会暴露各自的数据。在实体对齐过程中，系统不会公开彼此不重叠的用户。

**PART 2：** 加密模型训练。在确定了公共实体之后，我们可以使用这些公共实体的数据来训练机器学习模型。训练过程可分为以下四个步骤（如图4所示）：

第一步：第三方合作者 C 创建加密对，将公钥发送给 A 和 B；  
第二步：A、B 对梯度和损失计算需要的中间结果进行加密与交换；  
第三步：A、B 分别计算加密梯度并添加额外的掩码，B 也计算加密损失；A 和 B 向 C 发送加密值；  
第四步：C 解密并将解密后的梯度和损失发送回 A、B；A 和 B 除去梯度上的掩码，相应地更新模型参数。

## 3. 联邦迁移学习（Federated Transfer Learning）

**联邦迁移学习适用于两个数据集不仅在样本上不同，而且在特征空间也不同的场景。**  
考虑两个机构，一个是位于中国的银行，另一个是位于美国的电子商务公司。  
由于地域的限制，两个机构的用户群有一个小的交叉点。另一方面，由于业务的不同，双方的功能空间只有一小部分重叠。  
在这种情况下，可以应用迁移学习技术为联邦下的整个样本和特征空间提供解决方案。  
特别地，使用有限的公共样本集学习两个特征空间之间的公共表示，然后应用于获取仅具有单侧特征的样本预测。

